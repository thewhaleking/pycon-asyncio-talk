{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:46:32.311256Z",
     "start_time": "2026-02-21T09:46:32.308910Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "from utils.go_fast import crunch as cy_crunch\n",
    "from utils.pure import crunch as py_crunch\n",
    "from server import Server, RecordKeeper\n",
    "\n",
    "server = Server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cfaefac76ad827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:33:47.227402Z",
     "start_time": "2026-02-21T09:33:47.224987Z"
    }
   },
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def timeit():\n",
    "    loop = asyncio.get_running_loop()\n",
    "    start = loop.time()\n",
    "    yield\n",
    "    end = loop.time()\n",
    "    print(f\"{(end - start):.2f}\", \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f883dd53d6e0c16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:46:35.496032Z",
     "start_time": "2026-02-21T09:46:34.991308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 seconds\n"
     ]
    }
   ],
   "source": [
    "async def single():\n",
    "    \"\"\"\n",
    "    What most people who start writing asyncio do\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data = await server.get()\n",
    "\n",
    "\n",
    "await single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c8a7ed0ea446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def sequential():\n",
    "    \"\"\"\n",
    "    How most people continue writing asyncio\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data = await server.get()\n",
    "        data2 = await server.get()\n",
    "\n",
    "\n",
    "await sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e6655a5f6c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def use_gather():\n",
    "    \"\"\"\n",
    "    Gathering. The first asyncio optimisation you've probably used\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data, data2 = await asyncio.gather(server.get(), server.get())\n",
    "\n",
    "\n",
    "await use_gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611446df0011ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def py_processing():\n",
    "    \"\"\"\n",
    "    How you might write some data processing with asyncio\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data1 = await server.get()\n",
    "        py_crunch(data1)\n",
    "        data2 = await server.get()\n",
    "        py_crunch(data2)\n",
    "\n",
    "\n",
    "await py_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd4014eff9e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cy_processing():\n",
    "    \"\"\"\n",
    "    When you want CPU-bound speed, you write in Cython (or similar)\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data1 = await server.get()\n",
    "        cy_crunch(data1)\n",
    "        data2 = await server.get()\n",
    "        cy_crunch(data2)\n",
    "\n",
    "\n",
    "await cy_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2888c9b0cb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_and_py():\n",
    "    \"\"\"\n",
    "    You've optimised your data pull, but it's not as fast as it could be\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data, data2 = await asyncio.gather(server.get(), server.get())\n",
    "        py_crunch(data2)\n",
    "        py_crunch(data)\n",
    "\n",
    "\n",
    "await gather_and_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add39f6ad55086a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_and_cy():\n",
    "    \"\"\"\n",
    "    You've optimised your data pull, and the data processing. Can't get much faster, right?\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data, data2 = await asyncio.gather(server.get(), server.get())\n",
    "        cy_crunch(data2)\n",
    "        cy_crunch(data)\n",
    "\n",
    "\n",
    "await gather_and_cy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881c98b34a150e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_and_cy_to_thread():\n",
    "    \"\"\"\n",
    "    Any extension that releases the GIL will allow us to utilise threading to improve CPU-bound\n",
    "    code\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        data, data2 = await asyncio.gather(server.get(), server.get())\n",
    "        await asyncio.gather(\n",
    "            asyncio.to_thread(cy_crunch, data), asyncio.to_thread(cy_crunch, data2)\n",
    "        )\n",
    "\n",
    "\n",
    "await gather_and_cy_to_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d4f9ee9414c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def restrict_executor():\n",
    "    \"\"\"\n",
    "    Demonstrates differently using the loop executor\n",
    "    \"\"\"\n",
    "    async with timeit():\n",
    "        loop = asyncio.get_running_loop()\n",
    "        executor = ThreadPoolExecutor(max_workers=1)\n",
    "        data, data2 = await asyncio.gather(server.get(), server.get())\n",
    "        await asyncio.gather(\n",
    "            loop.run_in_executor(executor, cy_crunch, data),\n",
    "            loop.run_in_executor(executor, cy_crunch, data2),\n",
    "        )\n",
    "    input(\"Waiting\")\n",
    "    async with timeit():\n",
    "        # Note we can also assign the executor to the whole loop\n",
    "        loop.set_default_executor(executor)\n",
    "        data, data2 = await asyncio.gather(server.get(), server.get())\n",
    "        await asyncio.gather(\n",
    "            asyncio.to_thread(cy_crunch, data), asyncio.to_thread(cy_crunch, data2)\n",
    "        )\n",
    "    input(\"Waiting\")\n",
    "    # there's virtually no speed difference here because we're only using 2 items. Let's increase that\n",
    "    loop.set_default_executor(None)  # clear the default executor\n",
    "    async with timeit():\n",
    "        data_list = await asyncio.gather(*[server.get() for _ in range(1_000)])\n",
    "        await asyncio.gather(*[asyncio.to_thread(cy_crunch, d) for d in data_list])\n",
    "    # that's pretty fast. But we don't want to utilise the breadth of our threads\n",
    "    input(\"Waiting\")\n",
    "    async with timeit():\n",
    "        loop.set_default_executor(executor)\n",
    "        data_list = await asyncio.gather(*[server.get() for _ in range(1_000)])\n",
    "        await asyncio.gather(*[asyncio.to_thread(cy_crunch, d) for d in data_list])\n",
    "\n",
    "\n",
    "await restrict_executor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430f3c664d338f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def semaphore():\n",
    "    \"\"\"\n",
    "    Use a semaphore to restrict your throughput\n",
    "    \"\"\"\n",
    "    sema4 = asyncio.Semaphore(20)\n",
    "\n",
    "    async def fetcher(sem: asyncio.Semaphore | None) -> int:\n",
    "        if sem is None:\n",
    "            return await server.get()\n",
    "        else:\n",
    "            async with sem:\n",
    "                return await server.get()\n",
    "\n",
    "    print(\"Without semaphore\")\n",
    "    async with timeit():\n",
    "        async with asyncio.TaskGroup() as tg:\n",
    "            tasks = set()\n",
    "            for _ in range(100):\n",
    "                tasks.add(tg.create_task(fetcher(None)))\n",
    "    input(\"Waiting\")\n",
    "    print(\"With semaphore\")\n",
    "    async with timeit():\n",
    "        async with asyncio.TaskGroup() as tg:\n",
    "            tasks = set()\n",
    "            for _ in range(100):\n",
    "                tasks.add(tg.create_task(fetcher(sema4)))\n",
    "\n",
    "\n",
    "await semaphore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8f688b1cc9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def use_queue():\n",
    "    \"\"\"\n",
    "    Using queues to manage the data pulling and processing\n",
    "    \"\"\"\n",
    "\n",
    "    async def consumer(\n",
    "        pro_q: asyncio.Queue[asyncio.Task[int]],\n",
    "        con_q: asyncio.Queue[asyncio.Task[float]],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        We use `None` in `pro_q` to indicate end (called a 'sentinel')\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            data = await pro_q.get()\n",
    "            if data is None:\n",
    "                break\n",
    "            task = loop.create_task(asyncio.to_thread(py_crunch, await data))\n",
    "            pro_q.task_done()\n",
    "            await con_q.put(task)\n",
    "\n",
    "    async with timeit():\n",
    "        loop = asyncio.get_running_loop()\n",
    "        results = []\n",
    "        producer_queue = asyncio.Queue()\n",
    "        consumer_queue = asyncio.Queue()\n",
    "        consumer_task = loop.create_task(consumer(producer_queue, consumer_queue))\n",
    "        for _ in range(101):\n",
    "            to_send = loop.create_task(server.get())\n",
    "            await producer_queue.put(to_send)\n",
    "        for idx in range(101):\n",
    "            results.append(await (await consumer_queue.get()))\n",
    "            if idx == 100:\n",
    "                # to shut it down\n",
    "                await producer_queue.put(None)\n",
    "        await consumer_task\n",
    "        print(f\"Completed {len(results)} tasks: {results}\")\n",
    "\n",
    "\n",
    "await use_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa5f7c3107ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def tasks_():\n",
    "    \"\"\"\n",
    "    Using tasks instead of just raw coroutines.\n",
    "\n",
    "    Tasks begin execution (usually) at the next iteration of the event loop\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    async with timeit():\n",
    "        query_tasks = [loop.create_task(server.get()) for _ in range(100)]\n",
    "        queried = await asyncio.gather(*query_tasks)\n",
    "        for task in queried:\n",
    "            cy_crunch(task)\n",
    "    async with timeit():\n",
    "        query_tasks = [loop.create_task(server.get()) for _ in range(100)]\n",
    "        queried = await asyncio.gather(*query_tasks)\n",
    "        await asyncio.gather(*[asyncio.to_thread(cy_crunch, task) for task in queried])\n",
    "\n",
    "\n",
    "await tasks_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298960d5c67c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def as_completed():\n",
    "    \"\"\"\n",
    "    Using `as_completed` to perform an action on tasks, as they complete\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    # by giving a set wait time, the tasks will all be received linearly (0 - 9)\n",
    "    query_tasks = [\n",
    "        loop.create_task(server.get(0.5), name=str(tsk)) for tsk in range(10)\n",
    "    ]\n",
    "    crunch_tasks = []\n",
    "    task: asyncio.Task[int]\n",
    "    print(len(query_tasks))\n",
    "    # Note: this only works on Python 3.13+\n",
    "    async for task in asyncio.as_completed(query_tasks):\n",
    "        print(\"Processing\", task.get_name())\n",
    "        crunch_tasks.append(asyncio.to_thread(cy_crunch, await task))\n",
    "    await asyncio.gather(*crunch_tasks)\n",
    "    input(\"Waiting\")\n",
    "    # passing `None` to `self.server.get` gives us a random wait time (0-1)\n",
    "    query_tasks = [\n",
    "        loop.create_task(server.get(None), name=str(tsk)) for tsk in range(10)\n",
    "    ]\n",
    "    crunch_tasks = []\n",
    "    task: asyncio.Task[int]\n",
    "    print(len(query_tasks))\n",
    "    async for task in asyncio.as_completed(query_tasks):\n",
    "        # demonstrates the non-linear order of completion\n",
    "        print(\"Processing\", task.get_name())\n",
    "        crunch_tasks.append(asyncio.to_thread(cy_crunch, await task))\n",
    "    await asyncio.gather(*crunch_tasks)\n",
    "\n",
    "\n",
    "await as_completed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623f72cc636f57f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:54:04.714496Z",
     "start_time": "2026-02-21T09:53:49.124734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent data 100\n",
      "Sent data 100\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Producer done\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Sent data 100\n",
      "Consumer done\n",
      "15.58 seconds\n"
     ]
    }
   ],
   "source": [
    "async def queue_excels(num_fetchers: int | str = 100, send_threshold: int = 1_000):\n",
    "    \"\"\"\n",
    "    Queues excel at situations like this where you need to constantly fetch data, but not\n",
    "    all at the same time\n",
    "\n",
    "    :param num_fetchers: Should be determined through your own benchmarking/profiling\n",
    "    \"\"\"\n",
    "    num_fetchers = int(num_fetchers)\n",
    "    loop = asyncio.get_running_loop()\n",
    "\n",
    "    async def producer(\n",
    "        prod_q: asyncio.Queue[int | None],\n",
    "        con_q: asyncio.Queue[asyncio.Task[int] | None],\n",
    "    ) -> None:\n",
    "        while True:\n",
    "            from_q = await prod_q.get()\n",
    "            if from_q is None:\n",
    "                return None\n",
    "            r = await server.get()\n",
    "            process_ = loop.create_task(asyncio.to_thread(cy_crunch, r))\n",
    "            await con_q.put(process_)\n",
    "            prod_q.task_done()\n",
    "\n",
    "    async def consumer(\n",
    "        con_q: asyncio.Queue[asyncio.Task[int] | None], send_threshold_: int = 1_000\n",
    "    ):\n",
    "        async def send(data_):\n",
    "            await server.post(data=data_)\n",
    "            print(\"Sent data\", len(data_))\n",
    "\n",
    "        to_send = []\n",
    "        while True:\n",
    "            try:\n",
    "                recd = await asyncio.wait_for(con_q.get(), 0.5)\n",
    "                if recd is None:\n",
    "                    if to_send:\n",
    "                        await send(to_send)\n",
    "                    return None\n",
    "                data = await recd\n",
    "                to_send.append(data)\n",
    "                con_q.task_done()\n",
    "            except TimeoutError:\n",
    "                if to_send:\n",
    "                    await send(to_send)\n",
    "                    to_send.clear()\n",
    "                continue\n",
    "\n",
    "            if len(to_send) >= send_threshold_:\n",
    "                await send(to_send)\n",
    "                to_send.clear()\n",
    "\n",
    "    producer_queue = asyncio.Queue()\n",
    "    consumer_queue = asyncio.Queue()\n",
    "\n",
    "    producer_tasks = [\n",
    "        loop.create_task(producer(producer_queue, consumer_queue))\n",
    "        for _ in range(num_fetchers)\n",
    "    ]\n",
    "    consumer_task = loop.create_task(\n",
    "        consumer(consumer_queue, send_threshold_=send_threshold)\n",
    "    )\n",
    "\n",
    "    async with timeit():\n",
    "        for num in range(1_000):\n",
    "            await producer_queue.put(num)\n",
    "        for _ in range(num_fetchers):\n",
    "            await producer_queue.put(None)\n",
    "        for t in producer_tasks:\n",
    "            await t\n",
    "            print(\"Producer done\")\n",
    "        await consumer_queue.put(None)\n",
    "        await consumer_task\n",
    "        print(\"Consumer done\")\n",
    "\n",
    "\n",
    "await queue_excels(send_threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d75e9df0a473009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:45:37.365136Z",
     "start_time": "2026-02-21T09:45:32.348496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching next page...\n",
      "876097\n",
      "195168\n",
      "345991\n",
      "722530\n",
      "356581\n",
      "527492\n",
      "365784\n",
      "925611\n",
      "990451\n",
      "544932\n",
      "Fetching next page...\n",
      "910809\n",
      "164646\n",
      "186372\n",
      "160800\n",
      "584825\n",
      "517477\n",
      "741369\n",
      "889727\n",
      "914007\n",
      "367736\n",
      "Fetching next page...\n",
      "552838\n",
      "541731\n",
      "94793\n",
      "913067\n",
      "846606\n",
      "795522\n",
      "545115\n",
      "351258\n",
      "641094\n",
      "77836\n",
      "Fetching next page...\n",
      "557204\n",
      "971433\n",
      "567675\n",
      "851969\n",
      "802926\n",
      "683102\n",
      "926350\n",
      "190673\n",
      "780529\n",
      "460927\n",
      "Fetching next page...\n",
      "454323\n",
      "302782\n",
      "673426\n",
      "795142\n",
      "178156\n",
      "268183\n",
      "888575\n",
      "982245\n",
      "341467\n",
      "404107\n",
      "Fetching next page...\n",
      "820620\n",
      "42508\n",
      "897625\n",
      "566598\n",
      "825280\n",
      "640347\n",
      "916423\n",
      "807597\n",
      "474367\n",
      "407914\n",
      "Fetching next page...\n",
      "249448\n",
      "316917\n",
      "671102\n",
      "623430\n",
      "596657\n",
      "228910\n",
      "263987\n",
      "527809\n",
      "576226\n",
      "610746\n",
      "Fetching next page...\n",
      "844125\n",
      "465847\n",
      "179673\n",
      "918975\n",
      "736963\n",
      "664635\n",
      "696515\n",
      "416742\n",
      "634017\n",
      "97769\n",
      "Fetching next page...\n",
      "800770\n",
      "174744\n",
      "371137\n",
      "470576\n",
      "416278\n",
      "268632\n",
      "70732\n",
      "688486\n",
      "395676\n",
      "543345\n",
      "Fetching next page...\n",
      "94861\n",
      "544764\n",
      "909949\n",
      "306260\n",
      "492974\n",
      "389449\n",
      "196084\n",
      "576795\n",
      "45776\n",
      "301779\n"
     ]
    }
   ],
   "source": [
    "async def async_for(page_size: int = 10, max_records: int = 100):\n",
    "    \"\"\"\n",
    "    Having an interator that automatically runs a next async fetch can be highly useful\n",
    "    \"\"\"\n",
    "    records: RecordKeeper = await server.records(page_size, max_records)\n",
    "    async for record in records:\n",
    "        print(record)\n",
    "\n",
    "\n",
    "await async_for()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
